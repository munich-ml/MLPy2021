{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "nav_menu": {
      "height": "264px",
      "width": "369px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "31_fMNIST_classifier_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/munich-ml/MLPy2021/blob/main/31_fMNIST_classifier_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2piuI4C-TVp"
      },
      "source": [
        "# Intro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9_a-EzZ6x8B"
      },
      "source": [
        "## References\n",
        "Resources used to create this notebook:\n",
        "- [scikit-learn website](https://scikit-learn.org)\n",
        "- [Matplotlib website](https://matplotlib.org/)\n",
        "- [Wikipedia](https://en.wikipedia.org/wiki/Main_Page)\n",
        "- Hands-on Machine Learning with Scikit-learn, Keras & TensorFlow, Aurelien Geron, [Book on Amazon](https://www.amazon.de/Aur%C3%A9lien-G%C3%A9ron/dp/1492032646/ref=sr_1_3?__mk_de_DE=%C3%85M%C3%85%C5%BD%C3%95%C3%91&dchild=1&keywords=Hands-on+Machine+Learning+with+Scikit-learn%2C+Keras+%26+TensorFlow%2C+Aurelien+Geron%2C&qid=1589875241&sr=8-3)\n",
        "- Introduction to Machine Learning with Python, Andreas Mueller, [Book on Amazon](https://www.amazon.de/Introduction-Machine-Learning-Python-Scientists/dp/1449369413)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNST_MlxjzH0"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgdeO6WVjzH0"
      },
      "source": [
        "First, do the common imports.\n",
        "\n",
        "Tensorflow must be 2.x, because there are major changes from 1.x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yPHaPsejzH1"
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Common imports\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# Setup matplotlib\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Ignore useless warnings (see SciPy issue #5998)\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "in_colab = 'google.colab' in sys.modules   # check if note is executed within Colab\n",
        "\n",
        "# Forces tensorflow version (only in colab)\n",
        "if in_colab:\n",
        "    %tensorflow_version 2.x           \n",
        "\n",
        "# Clone the repository if executed in Google Colab\n",
        "if in_colab:  \n",
        "    if \"MLPy2021\" in os.listdir():\n",
        "        !git -C MLPy2021 pull\n",
        "    else:\n",
        "        !git clone https://github.com/munich-ml/MLPy2021/\n",
        "\n",
        "# lib.helper_funcs.py. The import path depends on Colab or local execution \n",
        "if in_colab:\n",
        "    from MLPy2021.lib.helper_funcs import pickle_out\n",
        "else: \n",
        "    from lib.helper_funcs import pickle_out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AExVh3ZXjzIM"
      },
      "source": [
        "# Get the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSTBrdRijzIT"
      },
      "source": [
        "**MNIST** is probably **THE classical dataset for image recognition**. \n",
        "\n",
        "A more challanging dataset is the **[fashion MNIST](https://github.com/zalandoresearch/fashion-mnist)** from Zalando.\n",
        "\n",
        "``tf.keras`` already includes [fashion MNIST](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist/load_data) and some other popular datasets in `keras.datasets`. \n",
        "\n",
        "The fashion MNIST dataset is already split into a training set and a test set, but it can be useful to split the training set further to have a validation set:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5knEMVQjzIU"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuZcvkBxjzIn"
      },
      "source": [
        "From the [dataset documentation](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist/load_data) we know, that the **labels** are **class IDs** that correspond to the following **`class_names`**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmS0brgljzIo"
      },
      "source": [
        "class_names = [\"T-shirt\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AohFjDO7rWa"
      },
      "source": [
        "y_train_full[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5haYdhQZjzIq"
      },
      "source": [
        "class_names[y_train_full[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLCceLIoh0FV"
      },
      "source": [
        "Plot part of the dataset to get an overview\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5w1HgKtjzIw"
      },
      "source": [
        "# code for viewing, not for teaching\n",
        "n_rows, n_cols = 5, 12\n",
        "plt.figure(figsize=(n_cols*1.2, n_rows*1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index+1)\n",
        "        plt.imshow(X_train_full[index], cmap=plt.cm.binary, interpolation=\"nearest\")\n",
        "        plt.title(\"{} {}\".format(index, class_names[y_train_full[index]]), fontsize=12)\n",
        "        plt.axis('off')\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqcw-1PbB59C"
      },
      "source": [
        "##Inpect the data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jWZzLRVjzIW"
      },
      "source": [
        "The training set contains 60,000 grayscale images, each 28x28 pixels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xuF9Jx5jzIX"
      },
      "source": [
        "X_train_full.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM6pJgYP9OpE"
      },
      "source": [
        "sample_img = X_train_full[100, :, :]\n",
        "sample_img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmdaXHeljzId"
      },
      "source": [
        "One may plot an image using Matplotlib's `imshow()` function::"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6tiZAlmNoE7"
      },
      "source": [
        "plt.imshow(sample_img, cmap=plt.cm.binary);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ges7UgA1jzIY"
      },
      "source": [
        "Each pixel intensity is an 8bit interger value.\n",
        "- 0 is white\n",
        "- 255 is black"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO9--c7bjzIZ"
      },
      "source": [
        "sample_img.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lFmSDPU-CAI"
      },
      "source": [
        "pd.Series(sample_img.flatten()).value_counts().sort_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzUAOKou_Oqx"
      },
      "source": [
        "sample_img[:,:13]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H96qOJScTD3"
      },
      "source": [
        "## Scale the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGA6Zhd9cbEU"
      },
      "source": [
        "Since we are going to train the neural network using **Gradient Descent**, we must scale the input features. \n",
        "\n",
        "The ``SciKit-learn MinMaxScaler`` doesn't work for 2D-features. Therefore, let's implement a simple Max Scaler with ``SciKit-learn`` compliant interface:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIM0XWkZtnrv"
      },
      "source": [
        "from sklearn.base import TransformerMixin,BaseEstimator\n",
        "\n",
        "class MaxScaler(BaseEstimator,TransformerMixin):\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self._scale = X.max()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X / self._scale"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEK11t-w18w9"
      },
      "source": [
        "scaler = MaxScaler()\n",
        "X_train_full = scaler.fit_transform(X_train_full)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVZ-HlJu05Fe"
      },
      "source": [
        "X_train_full.max(), X_test.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPqqIaWmDKuR"
      },
      "source": [
        "##Split a validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juKEC0CIjzIb"
      },
      "source": [
        "Let's split the *full training set* into a *validation set* and a (smaller) *training set*. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FduVxwIr8VTZ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, \n",
        "                                                      test_size=5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KtBD7Rb8BR0"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPD9JgDi8BPC"
      },
      "source": [
        "X_valid.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCSPDApc8BMu"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmK80Zw5-PA8"
      },
      "source": [
        "plt.figure(figsize=(12,3))\n",
        "for i, label in enumerate([\"y_train_full\", \"y_train\", \"y_valid\"]):\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    plt.plot(eval(label+\"[:500]\"), \"d\")\n",
        "    plt.yticks(range(len(class_names)), labels=class_names)\n",
        "    plt.title(label), plt.tight_layout();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nt1J1_8DjLhE"
      },
      "source": [
        "# Build a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KcSVtvPk2eS"
      },
      "source": [
        "The folloging  code creates a **classification MLP** (multi layer perceptron) with 2 hidden layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1jDkmA4jzIy"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4Ok1P0wnglp"
      },
      "source": [
        "Alternatively to using `model.add` we can pass a list of layers to the `Sequential()` constructor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYEvpHvHjzI0"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(47)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr_-O_6NjzI2"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=keras.activations.relu),\n",
        "    keras.layers.Dense(100, activation=keras.activations.relu),\n",
        "    keras.layers.Dense(10, activation=keras.activations.softmax)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WtDyf3gtUHk"
      },
      "source": [
        "keras.activations.relu([-2, -1, 0, 1, 2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_h-eCRNU9wL"
      },
      "source": [
        "## Model summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "079O7pFlooUk"
      },
      "source": [
        "Let's print a summary of the model, using `model.summary()`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjt1mbX7jzI6"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmEmbawQqQf9"
      },
      "source": [
        "Note the huge amount of (trainable) parameters. For example, the first hidden layer has 784 * 300 connection weights, plus 300 bias terms. This gives the model quite a flexibility to fit the training data, but it's also prone to overfitting, especially with few traning data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RdzQ099jzI8"
      },
      "source": [
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1J_AUPxoJ7Z"
      },
      "source": [
        "The layers of the model can be accessed with `model.layers`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEe8Hx3kjzI-"
      },
      "source": [
        "for i, layer in enumerate(model.layers):\n",
        "    print(\"layer {}: {}\".format(i, layer.name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQcLija2jzJB"
      },
      "source": [
        "weights, biases = model.layers[2].get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_8DGrX8jzJE"
      },
      "source": [
        "weights.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIrDFhiAjzJC"
      },
      "source": [
        "weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6xBSop2jzJI"
      },
      "source": [
        "biases.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFFf8n0TjzJG"
      },
      "source": [
        "biases"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOpWho9UVHvU"
      },
      "source": [
        "Note that the biases are initialized with zeros while the weights are initalized randomly. This is required to support convergence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w2YhxoSjYu3"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORbe2bMijzJK"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"sgd\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLXl80keSno-"
      },
      "source": [
        "model.compile?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zyxcIEkjzJL"
      },
      "source": [
        "This is equivalent to:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avfNnVgSjzJM"
      },
      "source": [
        "```\n",
        "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.SGD(),\n",
        "              metrics=[keras.metrics.sparse_categorical_accuracy])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4uCNLQCyR5a"
      },
      "source": [
        "Some explanation to the `compile` params:\n",
        "- The loss must be **sparse_**categorical_crossentropy because the labels are sparse, meaning just one value per training instance and not a tensor of len(10)\n",
        "- The optimizer is a simple **Stochastic Gradient Descent**\n",
        "- Since this is a **classifier**, it's useful to measure **accuracy** during training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xup3H4K0MzP"
      },
      "source": [
        "Now, let's kick-off training using `model.fit`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWwdFlwKjzJM"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=30, verbose=1,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82xvP3IkjzJO"
      },
      "source": [
        "history.params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkTY_2SoH0TA"
      },
      "source": [
        "history.history.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvRcpf0oGEuR"
      },
      "source": [
        "plt.figure(figsize=[10, 3]) \n",
        "for i, word in enumerate([\"loss\", \"accuracy\"]):\n",
        "    plt.subplot(1, 2, i+1)\n",
        "    for key, vals in history.history.items():\n",
        "        if word in key:\n",
        "            plt.plot(vals, label=key)\n",
        "    plt.grid(), plt.legend(), plt.title(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D23-to7G3HW"
      },
      "source": [
        "## Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44td_VNCHIp0"
      },
      "source": [
        "mount_dir = os.path.join(os.getcwd(), \"drive\")\n",
        "mount_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SOHBBtZG6Ul"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(mount_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4R-fkWQ7HahD"
      },
      "source": [
        "## model.save()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7DGgId6He21"
      },
      "source": [
        "save_dir = os.path.join(mount_dir, \"My Drive\", \"Colab Notebooks\", \"models\")\n",
        "save_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuLDVcknIwKu"
      },
      "source": [
        "os.path.isdir(save_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEmaH7azHexz"
      },
      "source": [
        "fn = \"fMNIST_NN_v1_ageron\"\n",
        "model.save(os.path.join(save_dir, fn + \".h5\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qq51fMtd2_vD"
      },
      "source": [
        "### Save validation and test data along with the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHXemS0IhA2t"
      },
      "source": [
        "pickle_out(os.path.join(save_dir, fn+\"_data.pkl\"), locals(),\n",
        "           X_valid, y_valid, X_test, y_test, class_names)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}