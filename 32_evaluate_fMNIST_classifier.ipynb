{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "nav_menu": {
      "height": "264px",
      "width": "369px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "32_evaluate_fMNIST_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/munich-ml/MLPy2021/blob/main/32_evaluate_fMNIST_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2piuI4C-TVp"
      },
      "source": [
        "# Intro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9_a-EzZ6x8B"
      },
      "source": [
        "## References\n",
        "Resources used to create this notebook:\n",
        "- [scikit-learn website](https://scikit-learn.org)\n",
        "- [Matplotlib website](https://matplotlib.org/)\n",
        "- [Wikipedia](https://en.wikipedia.org/wiki/Main_Page)\n",
        "- Hands-on Machine Learning with Scikit-learn, Keras & TensorFlow, Aurelien Geron, [Book on Amazon](https://www.amazon.de/Aur%C3%A9lien-G%C3%A9ron/dp/1492032646/ref=sr_1_3?__mk_de_DE=%C3%85M%C3%85%C5%BD%C3%95%C3%91&dchild=1&keywords=Hands-on+Machine+Learning+with+Scikit-learn%2C+Keras+%26+TensorFlow%2C+Aurelien+Geron%2C&qid=1589875241&sr=8-3)\n",
        "- Introduction to Machine Learning with Python, Andreas Mueller, [Book on Amazon](https://www.amazon.de/Introduction-Machine-Learning-Python-Scientists/dp/1449369413)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNST_MlxjzH0"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgdeO6WVjzH0"
      },
      "source": [
        "First, do the common imports.\n",
        "\n",
        "Tensorflow must be 2.x, because there are major changes from 1.x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yPHaPsejzH1"
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Common imports\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# Setup matplotlib\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Ignore useless warnings (see SciPy issue #5998)\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "in_colab = 'google.colab' in sys.modules   # check if note is executed within Colab\n",
        "\n",
        "# Forces tensorflow version (only in colab)\n",
        "if in_colab:\n",
        "    %tensorflow_version 2.x           \n",
        "\n",
        "# Clone the repository if executed in Google Colab\n",
        "if in_colab:  \n",
        "    if \"MLPy2021\" in os.listdir():\n",
        "        !git -C MLPy2021 pull\n",
        "    else:\n",
        "        !git clone https://github.com/munich-ml/MLPy2021/\n",
        "\n",
        "# lib.helper_funcs.py. The import path depends on Colab or local execution \n",
        "if in_colab:\n",
        "    from MLPy2021.lib.helper_funcs import plot_confusion_matrix, plot_prediction_examples, pickle_in\n",
        "else: \n",
        "    from lib.helper_funcs import plot_confusion_matrix, plot_prediction_examples, pickle_in\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl-ClkTnq1nV"
      },
      "source": [
        "# Load a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp2b1spIJJ3v"
      },
      "source": [
        "## Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44td_VNCHIp0"
      },
      "source": [
        "mount_dir = os.path.join(os.getcwd(), \"drive\")\n",
        "mount_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SOHBBtZG6Ul"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(mount_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4R-fkWQ7HahD"
      },
      "source": [
        "## load_model()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7DGgId6He21"
      },
      "source": [
        "save_dir = os.path.join(mount_dir, \"My Drive\", \"Colab Notebooks\", \"models\")\n",
        "os.listdir(save_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_zNmei3q36I"
      },
      "source": [
        "fn = \"fMNIST_NN_v1_ageron\"\t\n",
        "model = keras.models.load_model(os.path.join(save_dir, fn + \".h5\"))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS2bXvR7t67p"
      },
      "source": [
        "## Load the validation and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtiC98eepLZR"
      },
      "source": [
        "print([var for var in vars() if not var.startswith(\"_\")])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCk7TCxip40n"
      },
      "source": [
        "pickle_in(os.path.join(save_dir, fn+'_data.pkl'), locals())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV8KRsq2p4yJ"
      },
      "source": [
        "print([var for var in vars() if not var.startswith(\"_\")])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZmA-b_hD-k1"
      },
      "source": [
        "class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUexjQMAEF-j"
      },
      "source": [
        "X_valid.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-EncvSDqkUk"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib4LMypVjK2b"
      },
      "source": [
        "# Evaluate the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhWLInLr6kDk"
      },
      "source": [
        "###model.evaluate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEXqxVwt6Akk"
      },
      "source": [
        "`model.evaluate()` predicts restults on the testset and computes loss and metrics with respect to the expected results  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPVgUsj7jzJW"
      },
      "source": [
        "model.evaluate(X_valid, y_valid);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sws5qtAd6o8X"
      },
      "source": [
        "### model.predict()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUiWSt4MjzJZ"
      },
      "source": [
        "pd.options.display.float_format = '{:,.2f}'.format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWoI4YkYEusL"
      },
      "source": [
        "y_proba = model.predict(X_valid[:5])\n",
        "pd.DataFrame(y_proba, columns=class_names).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy3mDqLh6ton"
      },
      "source": [
        "### model.predict_classes()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWePKzCnQCDO"
      },
      "source": [
        "y_pred = model.predict_classes(X_valid)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHdJg5xVt4ty"
      },
      "source": [
        "np.array(class_names)[y_pred]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYBDRMpujzJg"
      },
      "source": [
        "some_indexes = [1, 2, 3, 4, 11, 12, 23]\n",
        "plt.figure(figsize=(13, 2.5))\n",
        "for col, index in enumerate(some_indexes):\n",
        "    plt.subplot(1, len(some_indexes), col+1)\n",
        "    plt.imshow(np.squeeze(X_valid[index]), cmap=\"binary\")\n",
        "    title = \"actl='{}'\\n\".format(class_names[y_valid[index]])\n",
        "    title +=\"pred='{}'\\n\".format(class_names[y_pred[index]])\n",
        "    plt.title(title, fontsize=11), plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnZ-K4W2jiRJ"
      },
      "source": [
        "## Confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpvZR4k13MRz"
      },
      "source": [
        "A confusion matrix is a two dimensional histogram of actual (rows) and predicted (cols) classes. \n",
        "- the main diagonal are correct predictions\n",
        "- all other entries are fails"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEdUTiv89JeQ"
      },
      "source": [
        "confusion = tf.math.confusion_matrix(y_valid, y_pred)\n",
        "confusion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLEFB7wF6oLI"
      },
      "source": [
        "###Exercise \n",
        "Previously, we computed the **accurary** using `model.evaluate()`. Accuracy is defined by:\n",
        "\n",
        "$\n",
        "\\text{accuracy} = \\cfrac{\\text{all}True}{\\text{all}} \n",
        "$ \n",
        "\n",
        "Check that result with the confusion matrix supported by **numpy**.\n",
        "\n",
        "\n",
        "Hint: The follwing line converts the **tensor** `confusion` into a **numpy array** and computes the sum of all items.\n",
        "```python\n",
        "np.array(confusion).sum()\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW5M0nnHICZu"
      },
      "source": [
        "### Plotting the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiU0p0PHwyU_"
      },
      "source": [
        "plot_confusion_matrix(confusion, xticks=class_names, yticks=class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTTpR1FP9mIm"
      },
      "source": [
        "Interpretation of the confusion matrix?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7OGfSUR9tlS"
      },
      "source": [
        "One usually focusses on the **false predictions**, thus ignoring the main diagonal may improve the visualization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrjmBYdI0IN3"
      },
      "source": [
        "plot_confusion_matrix(confusion, xticks=class_names, yticks=class_names, ignore_main_diagonal=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foDTUIy0oh13"
      },
      "source": [
        "## Performance measures for classifiers\n",
        "\n",
        "A **Digit-5 detector** is used as an example to compare different performance metrics:\n",
        "\n",
        "![](https://github.com/munich-ml/MLPy2021/blob/main/images/digit5-detector.png?raw=1)\n",
        "\n",
        "**True negative** for instance means:\n",
        "- **True**: The digit was classified correctly\n",
        "- **negative**: The digit is **not** a 5\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUTCnqzLMyxO"
      },
      "source": [
        "### Accuracy\n",
        "\n",
        "Accuracy is a good measure for symmetric datasets. It's definition again:\n",
        "\n",
        "$\n",
        "\\text{accuracy} = \\cfrac{\\text{all}True}{\\text{all}} \n",
        "$ \n",
        "\n",
        "If the counts of **false negatives** greatly differ from the **false positives** of if their costs is greatly different, alternative performance measures are required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw5wi_65_0pD"
      },
      "source": [
        "### Precision\n",
        "Precision (ideally 1.0) is decreased by **false positives** (FP). FP means the prediction `True` is wrong.\n",
        "\n",
        "$\n",
        "\\text{precision} = \\cfrac{TP}{\\text{all}P} = \\cfrac{TP}{TP + FP}\n",
        "$\n",
        "\n",
        "Example application: *Email Spam Detection*\n",
        "FP (mail sorted out) is worse than FN (spam coming through)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rMMCqJ9jiAd"
      },
      "source": [
        "### Recall (or sensitivity)\n",
        "Recall (ideally 1.0) says how good a model is at detecting the positives. \n",
        "\n",
        "Recall is decreased by **false negatives** (FN). FN means the prediction `False` is wrong.\n",
        "\n",
        "$\n",
        "\\text{recall} = \\cfrac{TP}{\\text{all}T} = \\cfrac{TP}{TP + FN}\n",
        "$\n",
        "\n",
        "Example application: *Medical Diabetic Detection*\n",
        "\n",
        "FN (Diabetic not detected) is worse than FP (Diabetic detected but patient is healthy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPaWgq2Kl_y9"
      },
      "source": [
        "### Specificity \n",
        "Specificity says how good a model is at detecting the negatives (avoiding false alarms).\n",
        "$\n",
        "\\text{specificity} = \\cfrac{TN}{\\text{all}N} = \\cfrac{TN}{TN + FP}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrtzGnEnpm7H"
      },
      "source": [
        "### F1-score\n",
        "*Harmonic mean* of precision and recall. \n",
        "\n",
        "$\n",
        "F_1 = \\cfrac{2}{{precision^{-1}} + {recall^{-1}}} = 2 \\times \\cfrac{\\text{precision}\\, \\times \\, \\text{recall}}{\\text{precision}\\, + \\, \\text{recall}} \n",
        "$\n",
        "\n",
        "Whereas *regular mean* treats all values equally, the *harmonic mean* gives more weight to low values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgefMZnE8i64"
      },
      "source": [
        "Evaluating the **Digit-5 detector** for the various metrics\n",
        "\n",
        "![](https://github.com/munich-ml/MLPy2021/blob/main/images/precision-recall.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXEAzPviPsk7"
      },
      "source": [
        "tn, fp, fn,tp = 5, 1, 2, 3\n",
        "\n",
        "perf = {}\n",
        "perf[\"accuracy\"] = (tp+tn) / (tp+tn+fp+fn)\n",
        "perf[\"precision\"] = tp / (tp+fp)\n",
        "perf[\"recall\"] = tp / (tp+fn)\n",
        "perf[\"specificity\"] = tn / (tn+fp)\n",
        "perf[\"F1-score\"] = 2 * perf[\"precision\"]*perf[\"recall\"] / (perf[\"precision\"]+perf[\"recall\"])\n",
        "\n",
        "for label, value in perf.items():\n",
        "    print(\"{:12s}{:.0%}\".format(label, value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO2UDfxVpLkR"
      },
      "source": [
        "## Classification report of the FMNIST-model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Og4W-uO4FdE"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_valid, y_pred, target_names=class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTxB2PdBw46Z"
      },
      "source": [
        "### Exercise \n",
        "Check the *precision* and *recall* values returned by `classification_report()` for one class (e.g. 'Coat')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDdnpYYOx5zp"
      },
      "source": [
        "####Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMrNwf2ZTxHj"
      },
      "source": [
        "plot_confusion_matrix(confusion, xticks=class_names, yticks=class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK05F2wFrNhg"
      },
      "source": [
        "CLASS_LABEL = \"Coat\"\n",
        "idx = class_names.index(CLASS_LABEL)\n",
        "idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47lCCBHTWG9D"
      },
      "source": [
        "type(confusion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA05XmlVWP86"
      },
      "source": [
        "Convert the **Tensor** into a familiar **numpy array** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCRBPxXKr5mZ"
      },
      "source": [
        "cm = np.array(confusion)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvrkFJ9asbBw"
      },
      "source": [
        "tp = cm[idx, idx]\n",
        "tp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRJ9M1LHsza2"
      },
      "source": [
        "FP are all items predicted as ``CLASS_LABEL`` minus TP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puAwgXLEsg_s"
      },
      "source": [
        "all_positive_predictions = cm[:, idx].sum()\n",
        "fp = all_positive_predictions - tp\n",
        "fp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5PzHDmWuyNp"
      },
      "source": [
        "FN are all actual ``CLASS_LABEL`` items minus TP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ghx4cj2sf-O"
      },
      "source": [
        "fn = cm[idx, :].sum() - tp\n",
        "fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po0bb7D4sXWl"
      },
      "source": [
        "print(\"Class '{}': precision={:.2f}, recall={:.2f}\".format(CLASS_LABEL, tp/(tp+fp), tp/(tp+fn)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvkjhDZOWymb"
      },
      "source": [
        "**Conclusion**: The ``classification_report`` output is proven to be correct!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxGom7hXT5gF"
      },
      "source": [
        "## Examples of predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEi5tAPz6Ceb"
      },
      "source": [
        "Let's look at some examples of right and wrong predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFGSnkt5XROT"
      },
      "source": [
        "class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5niIhwOfCNkF"
      },
      "source": [
        "validation_class = 6\n",
        "plot_prediction_examples(validation_class, class_names, y_pred, y_valid, X_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80_OlMaMXGm0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}